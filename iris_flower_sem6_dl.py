# -*- coding: utf-8 -*-
"""Iris flower-sem6 DL.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RI9_Rz80z8uFxTrT79LRZPkVuN6Yi4oV
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount("/gdrive")
# %cd /gdrive

ls

cd/gdrive/My Drive/Iris flower

ls

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt
import os
from sklearn.preprocessing import LabelEncoder
import seaborn as sns
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier

input_path='/gdrive/My Drive/Iris flower/Iris.csv'
df=pd.read_csv(input_path)
df.head()

df.drop('Id',axis=1,inplace=True)
df.info()

plt.figure(figsize=(12,8))
sns.heatmap(df.corr(),annot=True,cmap=plt.cm.Spectral)

plt.figure(figsize=(10,5))
sns.countplot(x='Species',data=df)
plt.grid()

le=LabelEncoder()
df['Species_type']=le.fit_transform(df['Species'])

def scatterplot(X,Y):
    sns.scatterplot(data=df,x=X,y=Y,hue='Species')
    plt.title(X+" vs "+Y)
    plt.grid()
    plt.show()

plt.figure(figsize=(10,6))
scatterplot('SepalWidthCm','SepalLengthCm')
plt.figure(figsize=(10,6))
scatterplot('PetalWidthCm','PetalLengthCm')
plt.tight_layout()

sns.pairplot(df,hue='Species',palette='Dark2')

df.boxplot(by="Species_type", figsize=(12, 6))

df.drop('Species_type',axis=1).hist(edgecolor='black', linewidth=1.2)
fig=plt.gcf()
fig.set_size_inches(12,6)
plt.show()

X_train,X_test,Y_train,Y_test = train_test_split(df.drop(['Species_type','Species'],axis=1),df['Species_type'],test_size=0.25,random_state=8)

plt.figure(figsize=(8,5))
sns.countplot(x=Y_test)
plt.title("Count of each type in Testing Set")
plt.grid()
plt.figure(figsize=(8,5))
sns.countplot(x=Y_train)
plt.title("Count of each type in Training Set")
plt.grid()

models = ['random_forest','svm','decision_tree','logistic_regression','knn']
model_train_acc=[]
model_test_acc=[]

svm= SVC()
svm.fit(X_train,Y_train)
y_hat_train = svm.predict(X_train)
y_hat_test = svm.predict(X_test)
train_acc = np.round(accuracy_score(y_hat_train,Y_train),3)
test_acc =  np.round(accuracy_score(y_hat_test,Y_test),3)

model_train_acc.append(train_acc)
model_test_acc.append(test_acc)

print("Accuracy Score on train data using SVM: ",train_acc)
print("Accuracy Score on test data using SVM: ",test_acc)

rfc = RandomForestClassifier()
rfc.fit(X_train,Y_train)
y_hat_train = rfc.predict(X_train)
y_hat_test = rfc.predict(X_test)
train_acc = np.round(accuracy_score(y_hat_train,Y_train),3)
test_acc =  np.round(accuracy_score(y_hat_test,Y_test),3)

model_train_acc.append(train_acc)
model_test_acc.append(test_acc)

print("Accuracy Score on train data using RandomForest: ",train_acc)
print("Accuracy Score on test data using RandomForest: ",test_acc)

tree = DecisionTreeClassifier()
tree.fit(X_train,Y_train)
y_hat_train = tree.predict(X_train)
y_hat_test = tree.predict(X_test)
train_acc = np.round(accuracy_score(y_hat_train,Y_train),3)
test_acc =  np.round(accuracy_score(y_hat_test,Y_test),3)

model_train_acc.append(train_acc)
model_test_acc.append(test_acc)

print("Accuracy Score on train data using Decision tree: ",train_acc)
print("Accuracy Score on test data using Decision tree: ",test_acc)

lr = LogisticRegression(max_iter=200)
lr.fit(X_train,Y_train)
y_hat_train = lr.predict(X_train)
y_hat_test = lr.predict(X_test)
train_acc = np.round(accuracy_score(y_hat_train,Y_train),3)
test_acc =  np.round(accuracy_score(y_hat_test,Y_test),3)

model_train_acc.append(train_acc)
model_test_acc.append(test_acc)

print("Accuracy Score on train data using Logistic Regression: ",train_acc)
print("Accuracy Score on test data using Logistic Regression: ",test_acc)

def select_neighbors():
    knn_train_acc=[]
    knn_test_acc=[]
    for i in range(1,11):
        knn = KNeighborsClassifier(n_neighbors=i)
        knn.fit(X_train,Y_train)
        y_hat_train = knn.predict(X_train)
        y_hat_test = knn.predict(X_test)
        knn_train_acc.append(accuracy_score(y_hat_train,Y_train))
        knn_test_acc.append(accuracy_score(y_hat_test,Y_test))
        
    return knn_train_acc,knn_test_acc

knn_train,knn_test = select_neighbors()
x = np.linspace(1,10,10)

plt.figure(figsize=(10,4))
plt.plot(x,knn_test,color='red')
plt.title("Neighbors vs Accuracy on Test Data using KNN")
plt.xticks(x)
plt.grid()

plt.figure(figsize=(10,4))
plt.plot(x,knn_train,color='red')
plt.title("Neighbors vs Accuracy on Train Data using KNN")
plt.xticks(x)
plt.grid()

train_acc = np.round(knn_train[6],3)
test_acc = np.round(knn_test[6],3)

model_train_acc.append(train_acc)
model_test_acc.append(test_acc)

print("Accuracy Score on train data using KNN: ",train_acc)
print("Accuracy Score on test data using KNN: ",test_acc)

